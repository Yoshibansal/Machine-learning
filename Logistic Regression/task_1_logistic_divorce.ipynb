{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_1_logistic_divorce.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoshibansal/Machine-learning/blob/main/Logistic%20Regression/task_1_logistic_divorce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMHjtVPbyaKP"
      },
      "source": [
        "## Logistic Regression Model for Divorce Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kktr-4GPI5ou"
      },
      "source": [
        "## Part 1.1: Implement  logistic regression from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJi26z8awmSD"
      },
      "source": [
        "### Logistic regression\n",
        "Logistic regression uses an equation as the representation, very much like linear regression.\n",
        "\n",
        "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
        "\n",
        "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
        "\n",
        "#### Dataset\n",
        "The dataset is available at <strong>\"data/divorce.csv\"</strong> in the respective challenge's repo.<br>\n",
        "<strong>Original Source:</strong> https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br><br>\n",
        "\n",
        "[//]: # \"The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file.<br>\"\n",
        "\n",
        "\n",
        "#### Features (X)\n",
        "1. Atr1 - If one of us apologizes when our discussion deteriorates, the discussion ends. (Numeric | Range: 0-4)\n",
        "2. Atr2 - I know we can ignore our differences, even if things get hard sometimes. (Numeric | Range: 0-4)\n",
        "3. Atr3 - When we need it, we can take our discussions with my spouse from the beginning and correct it. (Numeric | Range: 0-4)\n",
        "4. Atr4 - When I discuss with my spouse, to contact him will eventually work. (Numeric | Range: 0-4)\n",
        "5. Atr5 - The time I spent with my wife is special for us. (Numeric | Range: 0-4)\n",
        "6. Atr6 - We don't have time at home as partners. (Numeric | Range: 0-4)\n",
        "7. Atr7 - We are like two strangers who share the same environment at home rather than family. (Numeric | Range: 0-4)\n",
        "\n",
        "&emsp;.<br>\n",
        "&emsp;.<br>\n",
        "&emsp;.<br>\n",
        "<br>\n",
        "54. Atr54 - I'm not afraid to tell my spouse about her/his incompetence. (Numeric | Range: 0-4)\n",
        "<br><br>\n",
        "Take a look above at the source of the original dataset for more details.\n",
        "\n",
        "#### Target (y)\n",
        "55. Class: (Binary | 1 => Divorced, 0 => Not divorced yet)\n",
        "\n",
        "#### Objective\n",
        "To gain understanding of logistic regression through implementing the model from scratch\n",
        "\n",
        "#### Tasks\n",
        "- Download and load the data (csv file contains ';' as delimiter)\n",
        "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias $w_0$\n",
        "- Define X matrix (independent features) and y vector (target feature) as numpy arrays\n",
        "- Print the shape and datatype of both X and y\n",
        "[//]: # \"- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction\"\n",
        "[//]: # \"- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (sklearn.preprocessing.StandardScaler)\"\n",
        "- Split the dataset into 85% for training and rest 15% for testing (sklearn.model_selection.train_test_split function)\n",
        "- Follow logistic regression class and fill code where highlighted:\n",
        "    - Write sigmoid function to predict probabilities\n",
        "    - Write cross entropy or log loss function (i.e. negative log likelihood)\n",
        "    - Write fit function where gradient descent is implemented\n",
        "    - Write predict_proba function where we predict probabilities for input data\n",
        "- Train the model\n",
        "- Write function for calculating accuracy\n",
        "- Compute accuracy on train and test data\n",
        "\n",
        "#### Further Fun (will not be evaluated)\n",
        "- Play with learning rate and max_iterations\n",
        "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
        "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
        "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
        "- Print other classification metrics such as:\n",
        "    - classification report (sklearn.metrics.classification_report),\n",
        "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
        "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
        "\n",
        "#### Helpful links\n",
        "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
        "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21J6cpd_wmSE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SL1fdNt1k3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e27e7ca-96a6-4dff-d0ac-edd296815ce9"
      },
      "source": [
        "# Download the dataset from the source\n",
        "!wget https://raw.githubusercontent.com/Yoshibansal/Machine-learning/main/Logistic%20Regression/data/divorce.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-18 04:12:57--  https://raw.githubusercontent.com/Yoshibansal/Machine-learning/main/Logistic%20Regression/data/divorce.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19021 (19K) [text/plain]\n",
            "Saving to: ‘divorce.csv’\n",
            "\n",
            "divorce.csv         100%[===================>]  18.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-18 04:12:57 (88.6 MB/s) - ‘divorce.csv’ saved [19021/19021]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9av7W-wowmSI"
      },
      "source": [
        "# Read the data from local cloud directory\n",
        "data = pd.read_csv('divorce.csv', sep=';')\n",
        "# Set delimiter to semicolon(;) in case of unexpected results"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmXolHwEI5o8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3ec9c739-9bd0-47c6-df7f-fb3c625197bc"
      },
      "source": [
        "# Add column which has all 1s\n",
        "# The idea is that weight corresponding to this column is equal to intercept\n",
        "# This way it is efficient and easier to handle the bias/intercept term\n",
        "data.insert(0, 'Bias', 1)\n",
        "data.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>Atr1</th>\n",
              "      <th>Atr2</th>\n",
              "      <th>Atr3</th>\n",
              "      <th>Atr4</th>\n",
              "      <th>Atr5</th>\n",
              "      <th>Atr6</th>\n",
              "      <th>Atr7</th>\n",
              "      <th>Atr8</th>\n",
              "      <th>Atr9</th>\n",
              "      <th>Atr10</th>\n",
              "      <th>Atr11</th>\n",
              "      <th>Atr12</th>\n",
              "      <th>Atr13</th>\n",
              "      <th>Atr14</th>\n",
              "      <th>Atr15</th>\n",
              "      <th>Atr16</th>\n",
              "      <th>Atr17</th>\n",
              "      <th>Atr18</th>\n",
              "      <th>Atr19</th>\n",
              "      <th>Atr20</th>\n",
              "      <th>Atr21</th>\n",
              "      <th>Atr22</th>\n",
              "      <th>Atr23</th>\n",
              "      <th>Atr24</th>\n",
              "      <th>Atr25</th>\n",
              "      <th>Atr26</th>\n",
              "      <th>Atr27</th>\n",
              "      <th>Atr28</th>\n",
              "      <th>Atr29</th>\n",
              "      <th>Atr30</th>\n",
              "      <th>Atr31</th>\n",
              "      <th>Atr32</th>\n",
              "      <th>Atr33</th>\n",
              "      <th>Atr34</th>\n",
              "      <th>Atr35</th>\n",
              "      <th>Atr36</th>\n",
              "      <th>Atr37</th>\n",
              "      <th>Atr38</th>\n",
              "      <th>Atr39</th>\n",
              "      <th>Atr40</th>\n",
              "      <th>Atr41</th>\n",
              "      <th>Atr42</th>\n",
              "      <th>Atr43</th>\n",
              "      <th>Atr44</th>\n",
              "      <th>Atr45</th>\n",
              "      <th>Atr46</th>\n",
              "      <th>Atr47</th>\n",
              "      <th>Atr48</th>\n",
              "      <th>Atr49</th>\n",
              "      <th>Atr50</th>\n",
              "      <th>Atr51</th>\n",
              "      <th>Atr52</th>\n",
              "      <th>Atr53</th>\n",
              "      <th>Atr54</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Bias  Atr1  Atr2  Atr3  Atr4  Atr5  ...  Atr50  Atr51  Atr52  Atr53  Atr54  Class\n",
              "0     1     2     2     4     1     0  ...      3      2      3      2      1      1\n",
              "1     1     4     4     4     4     4  ...      4      4      4      2      2      1\n",
              "2     1     2     2     2     2     1  ...      1      1      2      2      2      1\n",
              "3     1     3     2     3     2     3  ...      3      3      2      2      2      1\n",
              "4     1     2     2     1     1     1  ...      2      2      2      1      0      1\n",
              "\n",
              "[5 rows x 56 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV1jGAQxwmSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "fcb93782-a170-48f2-aaae-7c43bd5bf1ef"
      },
      "source": [
        "# Print the dataframe rows just to see some samples\n",
        "data[10:20]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>Atr1</th>\n",
              "      <th>Atr2</th>\n",
              "      <th>Atr3</th>\n",
              "      <th>Atr4</th>\n",
              "      <th>Atr5</th>\n",
              "      <th>Atr6</th>\n",
              "      <th>Atr7</th>\n",
              "      <th>Atr8</th>\n",
              "      <th>Atr9</th>\n",
              "      <th>Atr10</th>\n",
              "      <th>Atr11</th>\n",
              "      <th>Atr12</th>\n",
              "      <th>Atr13</th>\n",
              "      <th>Atr14</th>\n",
              "      <th>Atr15</th>\n",
              "      <th>Atr16</th>\n",
              "      <th>Atr17</th>\n",
              "      <th>Atr18</th>\n",
              "      <th>Atr19</th>\n",
              "      <th>Atr20</th>\n",
              "      <th>Atr21</th>\n",
              "      <th>Atr22</th>\n",
              "      <th>Atr23</th>\n",
              "      <th>Atr24</th>\n",
              "      <th>Atr25</th>\n",
              "      <th>Atr26</th>\n",
              "      <th>Atr27</th>\n",
              "      <th>Atr28</th>\n",
              "      <th>Atr29</th>\n",
              "      <th>Atr30</th>\n",
              "      <th>Atr31</th>\n",
              "      <th>Atr32</th>\n",
              "      <th>Atr33</th>\n",
              "      <th>Atr34</th>\n",
              "      <th>Atr35</th>\n",
              "      <th>Atr36</th>\n",
              "      <th>Atr37</th>\n",
              "      <th>Atr38</th>\n",
              "      <th>Atr39</th>\n",
              "      <th>Atr40</th>\n",
              "      <th>Atr41</th>\n",
              "      <th>Atr42</th>\n",
              "      <th>Atr43</th>\n",
              "      <th>Atr44</th>\n",
              "      <th>Atr45</th>\n",
              "      <th>Atr46</th>\n",
              "      <th>Atr47</th>\n",
              "      <th>Atr48</th>\n",
              "      <th>Atr49</th>\n",
              "      <th>Atr50</th>\n",
              "      <th>Atr51</th>\n",
              "      <th>Atr52</th>\n",
              "      <th>Atr53</th>\n",
              "      <th>Atr54</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Bias  Atr1  Atr2  Atr3  Atr4  ...  Atr51  Atr52  Atr53  Atr54  Class\n",
              "10     1     4     4     4     3  ...      4      4      4      4      1\n",
              "11     1     4     4     4     3  ...      4      4      4      4      1\n",
              "12     1     3     4     3     4  ...      4      4      4      4      1\n",
              "13     1     3     4     3     4  ...      4      4      4      4      1\n",
              "14     1     3     4     3     4  ...      4      4      4      4      1\n",
              "15     1     4     4     3     2  ...      4      4      4      4      1\n",
              "16     1     4     4     3     2  ...      4      4      4      4      1\n",
              "17     1     4     4     4     3  ...      3      4      3      4      1\n",
              "18     1     3     3     4     4  ...      4      4      4      4      1\n",
              "19     1     4     4     4     3  ...      3      4      3      4      1\n",
              "\n",
              "[10 rows x 56 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joRU6dWxwmSR"
      },
      "source": [
        "# Define X (input features) and y (output feature) \n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1:]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziY29OtH-Tj"
      },
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAyM-CYCwmSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be52b07-9e94-4ac2-9750-5d968845e963"
      },
      "source": [
        "X_shape = X.shape\n",
        "X_type  = type(X)\n",
        "y_shape = y.shape\n",
        "y_type  = type(y)\n",
        "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
        "print(f'y: Type-{y_type}, Shape-{y_shape}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)\n",
            "y: Type-<class 'numpy.ndarray'>, Shape-(170, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJrEelFzI5pA"
      },
      "source": [
        "<strong>Expected output: </strong><br><br>\n",
        "\n",
        "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)<br>\n",
        "y: Type-<class 'numpy.ndarray'>, Shape-(170,)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdLIVOm127-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e865d6-e426-45f5-bdce-37881fdff9a7"
      },
      "source": [
        "# Check and fill any missing values if any\n",
        "data.isnull().sum()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bias     0\n",
              "Atr1     0\n",
              "Atr2     0\n",
              "Atr3     0\n",
              "Atr4     0\n",
              "Atr5     0\n",
              "Atr6     0\n",
              "Atr7     0\n",
              "Atr8     0\n",
              "Atr9     0\n",
              "Atr10    0\n",
              "Atr11    0\n",
              "Atr12    0\n",
              "Atr13    0\n",
              "Atr14    0\n",
              "Atr15    0\n",
              "Atr16    0\n",
              "Atr17    0\n",
              "Atr18    0\n",
              "Atr19    0\n",
              "Atr20    0\n",
              "Atr21    0\n",
              "Atr22    0\n",
              "Atr23    0\n",
              "Atr24    0\n",
              "Atr25    0\n",
              "Atr26    0\n",
              "Atr27    0\n",
              "Atr28    0\n",
              "Atr29    0\n",
              "Atr30    0\n",
              "Atr31    0\n",
              "Atr32    0\n",
              "Atr33    0\n",
              "Atr34    0\n",
              "Atr35    0\n",
              "Atr36    0\n",
              "Atr37    0\n",
              "Atr38    0\n",
              "Atr39    0\n",
              "Atr40    0\n",
              "Atr41    0\n",
              "Atr42    0\n",
              "Atr43    0\n",
              "Atr44    0\n",
              "Atr45    0\n",
              "Atr46    0\n",
              "Atr47    0\n",
              "Atr48    0\n",
              "Atr49    0\n",
              "Atr50    0\n",
              "Atr51    0\n",
              "Atr52    0\n",
              "Atr53    0\n",
              "Atr54    0\n",
              "Class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En9Kb9dh2-wm"
      },
      "source": [
        "# Perform standarization (if required)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8WF-EqO3BEa"
      },
      "source": [
        "# Split the dataset into training and testing here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acCATJhI3FdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdb94e3-532c-44f4-a487-2c1f60913b7a"
      },
      "source": [
        "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
        "X_train_shape = X_train.shape\n",
        "y_train_shape = y_train.shape\n",
        "X_test_shape  = X_test.shape\n",
        "y_test_shape  = y_test.shape\n",
        "\n",
        "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
        "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
        "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (119, 55) , y_train: (119, 1)\n",
            "X_test: (51, 55) , y_test: (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSa7cW-NwmSd"
      },
      "source": [
        "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzxCdzxBI5pF"
      },
      "source": [
        "##### We will build a LogisticRegression class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgpspPcI5pH"
      },
      "source": [
        "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
        "# Let's try more object oriented approach this time :)\n",
        "class MyLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.001, max_iterations=1000):\n",
        "        '''Initialize variables\n",
        "        Args:\n",
        "            learning_rate  : Learning Rate\n",
        "            max_iterations : Max iterations for training weights\n",
        "        '''\n",
        "        # Initialising all the parameters\n",
        "        self.learning_rate  = learning_rate\n",
        "        self.max_iterations = max_iterations\n",
        "        self.cross_entropy_error    = [] # Summary of the cross entroy or log loss (i.e. negative log-likelihood)\n",
        "        \n",
        "        # Define epsilon because log(0) is not defined\n",
        "        self.eps = 1e-7\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        '''Sigmoid function: f:R->(0,1)\n",
        "        Args:\n",
        "            z : A numpy array (num_samples,)\n",
        "        Returns:\n",
        "            A numpy array where sigmoid function applied to every element\n",
        "        '''\n",
        "        ### START CODE HERE\n",
        "        sig_z = 1/(1+np.exp(-z))\n",
        "        ### END CODE HERE\n",
        "        \n",
        "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
        "        return sig_z\n",
        "    \n",
        "    def cross_entropy(self, y_true, y_pred):\n",
        "        '''Calculates cross_entropy or log loss (negative log-likelihood) estimate\n",
        "        Remember: -[y * log(yh) + (1-y) * log(1-yh)]\n",
        "        Note: Cross_entropy or log-loss is defined for multiple classes as well, but for this dataset\n",
        "        \n",
        "        Args:\n",
        "            y_true : Numpy array of actual truth values (num_samples,)\n",
        "            y_pred : Numpy array of predicted values (num_samples,)\n",
        "        Returns:\n",
        "            cross_entropy(or log loss which is the negative Log-likelihood) scalar value\n",
        "        '''\n",
        "        ### START CODE HERE\n",
        "        n = y_true.shape[0]\n",
        "        cross_entropy = (-1/n)*(np.sum((y_true*np.log(y_pred)) + ((1-y_true)*np.log(1-y_pred))))\n",
        "        ### END CODE HERE\n",
        "        \n",
        "        return cross_entropy\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''Trains logistic regression model using gradient descent\n",
        "        to gain minimum cross_entropy/log-loss on the training data\n",
        "        Args:\n",
        "            X : Numpy array (num_examples, num_features)\n",
        "            y : Numpy array (num_examples, )\n",
        "        Returns: VOID\n",
        "        '''\n",
        "        \n",
        "        num_examples = X.shape[0]\n",
        "        num_features = X.shape[1]\n",
        "        ### START CODE HERE\n",
        "        \n",
        "        # Initialize weights with appropriate shape\n",
        "        # self.weights = np.random.rand(1, num_features)\n",
        "        self.weights = np.ones((1, num_features))\n",
        "        \n",
        "        # Perform gradient descent\n",
        "        for i in range(self.max_iterations):\n",
        "            # Define the linear hypothesis(z) first\n",
        "            # HINT: what is our hypothesis function in linear regression, remember?\n",
        "            z = (1/num_examples)*np.dot(X, self.weights.T)\n",
        "\n",
        "            # Output probability value by appplying sigmoid on z\n",
        "            y_pred = self.sigmoid(z)\n",
        "            # print(y_pred)\n",
        "            # print(y_pred.shape)\n",
        "            \n",
        "            # Calculate the gradient values\n",
        "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
        "            gradient = np.mean((y-y_pred).T*X.T, axis=1).reshape(1,num_features)\n",
        "            # print(gradient)\n",
        "            # print(gradient.shape)\n",
        "            # Update the weights using gradient descent\n",
        "            self.weights = self.weights - self.learning_rate*gradient\n",
        "            \n",
        "            # Calculating cross entropy or log-loss (negatie log likelihood)\n",
        "            cross_entropy = self.cross_entropy(y, y_pred)\n",
        "\n",
        "            self.cross_entropy_error.append(cross_entropy)\n",
        "    \n",
        "        ### END CODE HERE\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        '''Predict probabilities for given X.\n",
        "        Remember sigmoid returns value between 0 and 1.\n",
        "        Args:\n",
        "            X : Numpy array (num_samples, num_features)\n",
        "        Returns:\n",
        "            probabilities: Numpy array (num_samples,)\n",
        "        '''\n",
        "        if self.weights is None:\n",
        "            raise Exception(\"Fit the model before prediction\")\n",
        "        \n",
        "        ### START CODE HERE\n",
        "        n = X.shape[0]\n",
        "        m = X.shape[1]\n",
        "        z = (1/n)*np.dot(X, self.weights.T)\n",
        "        probabilities = self.sigmoid(z)\n",
        "        ### END CODE HERE\n",
        "        \n",
        "        return probabilities\n",
        "    \n",
        "    def predict(self, X, threshold=0.7):\n",
        "        '''Predict/Classify X in classes\n",
        "        Args:\n",
        "            X         : Numpy array (num_samples, num_features)\n",
        "            threshold : scalar value above which prediction is 1 else 0\n",
        "        Returns:\n",
        "            binary_predictions : Numpy array (num_samples,)\n",
        "        '''\n",
        "        # Thresholding probability to predict binary values\n",
        "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
        "        # predictions = self.predict_proba(X)\n",
        "        \n",
        "        return binary_predictions"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crl6mGEoI5pJ"
      },
      "source": [
        "# Now initialize logitic regression implemented by you\n",
        "model = MyLogisticRegression()"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmMnrzPBI5pK"
      },
      "source": [
        "# And now fit on training data\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6tFOQTI5pL"
      },
      "source": [
        "##### Phew!! That's a lot of code. But you did it, congrats !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tvMc0OqwmSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0329be4e-739c-4780-c788-cd917a87f900"
      },
      "source": [
        "# Training cross entropy cost (or log-loss)\n",
        "train_cross_entropy = model.cross_entropy(y_train, model.predict_proba(X_train))\n",
        "print(\"Cross entropy cost on training data:\", train_cross_entropy)"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross entropy cost on training data: 0.5596025614714576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGViZYRDLcIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8df901-59a2-48ec-ae69-bfdc2723de40"
      },
      "source": [
        "# Testing cross entropy cost (or log-loss)\n",
        "test_cross_entropy = model.cross_entropy(y_test, model.predict_proba(X_test))\n",
        "print(\"Cross entropy cost on testing data:\", test_cross_entropy)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross entropy cost on testing data: 0.5399420016551577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vnjkAvzI5pN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "028cc3ce-f9cc-4fd1-93e1-52ce24186fea"
      },
      "source": [
        "# Plot the loss curve\n",
        "plt.plot([i+1 for i in range(len(model.cross_entropy_error))], model.cross_entropy_error)\n",
        "plt.title(\"Cross entropy error curve\")\n",
        "plt.xlabel(\"Iteration num\")\n",
        "plt.ylabel(\"Cross entropy (-ve log-likelihood)\")\n",
        "plt.show()"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH-ocni8I5pO"
      },
      "source": [
        "##### Let's calculate accuracy as well. Accuracy is defined simply as the rate of correct classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-RxIPbVI5pP"
      },
      "source": [
        "#Make predictions on test data\n",
        "y_pred = model.predict(X_train)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsS3PX65I5pP"
      },
      "source": [
        "def accuracy(y_true,y_pred):\n",
        "    '''Compute accuracy.\n",
        "    Accuracy = (Correct prediction / number of samples)\n",
        "    Args:\n",
        "        y_true : Truth binary values (num_examples, )\n",
        "        y_pred : Predicted binary values (num_examples, )\n",
        "    Returns:\n",
        "        accuracy: scalar value\n",
        "    '''\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    correct_predictions = np.sum(y_true.T == y_pred)\n",
        "    num_of_samples = len(y_true)\n",
        "    accuracy = correct_predictions/num_of_samples\n",
        "    ### END CODE HERE\n",
        "    return accuracy"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05SA_Ur6I5pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44abdb40-f023-453d-d254-5776a6d0952d"
      },
      "source": [
        "# Print accuracy on train data\n",
        "accuracy(y_train, y_pred)"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9495798319327731"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ0zLpChI5pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373661eb-ac0e-4a91-b706-478622854eb3"
      },
      "source": [
        "# Print accuracy on test data\n",
        "accuracy(y_test, model.predict(X_test))"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPU37tWAI5pR"
      },
      "source": [
        "## Part 1.2: Use Logistic Regression from sklearn on the same dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHscCs3bI5pR"
      },
      "source": [
        "#### Tasks\n",
        "- Define X and y again for sklearn Linear Regression model\n",
        "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
        "- Run the model on testing set\n",
        "- Print 'accuracy' obtained on the testing dataset (sklearn.metrics.accuracy_score function)\n",
        "\n",
        "#### Further fun (will not be evaluated)\n",
        "- Compare accuracies of your model and sklearn's logistic regression model\n",
        "\n",
        "#### Helpful links\n",
        "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcM8FakEI5pT"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP8AhS_vI5pT"
      },
      "source": [
        "# Define X and y\n",
        "X = \n",
        "y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc7htjejI5pU"
      },
      "source": [
        "# Initialize the model from sklearn\n",
        "model = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owIrjceyI5pU"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_YS9dn8I5pV"
      },
      "source": [
        "# Predict on testing set X_test\n",
        "y_pred = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pBqDQ0qI5pW"
      },
      "source": [
        "# Print Accuracy on testing set\n",
        "test_accuracy_sklearn = \n",
        "\n",
        "print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28hkMN_MI5pX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}